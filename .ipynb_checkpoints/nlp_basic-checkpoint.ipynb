{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 0. 준비물\n",
    "- python 환경\n",
    "    - 일반 python 환경\n",
    "    - docker\n",
    "- nltk : nlp toolkit\n",
    "    - pip install nltk\n",
    "    - nltk.download()\n",
    "- konlpy : nlp toolkit for Korean\n",
    "    - 사전 자바 설치 필요\n",
    "    - pip install konlpy\n",
    "    - pip install Jpype1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Basic Concept\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table\"><tbody><tr><th>English</th><th>한국어</th><th>Description</th></tr><tr><td>Document</td><td>문서</td><td>-</td></tr><tr><td>Corpus</td><td>말뭉치</td><td>A set of documents</td></tr><tr><td>Token</td><td>토큰</td><td>Meaningful elements in a text such as words or phrases or symbols</td></tr><tr><td>Morphemes</td><td>형태소</td><td>Smallest meaningful unit in a language</td></tr><tr><td>POS</td><td>품사</td><td>Part-of-speech (ex: Nouns)</td></tr></tbody></table>\n",
    "\n",
    "- 출처 : https://www.lucypark.kr/courses/2015-dm/text-mining.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. NLP in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = \"Mr. Kim, How are you? I'm fine. Thank you, and you?\"\n",
    "# 모두 몇개의 문장일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문장분리; End of Sentence(EOS) Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr', \" Kim, How are you? I'm fine\", ' Thank you, and you?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이브하게 접근한다면...\n",
    "texts.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr. Kim, How are you?', \"I'm fine.\", 'Thank you, and you?']\n"
     ]
    }
   ],
   "source": [
    "# nltk에 다 있음!\n",
    "sentences = nltk.tokenize.sent_tokenize(texts)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 토큰화; Tokenization \n",
    "- 문장을 토큰으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mr.', 'Kim', ',', 'How', 'are', 'you', '?'], ['I', \"'m\", 'fine', '.'], ['Thank', 'you', ',', 'and', 'you', '?']]\n"
     ]
    }
   ],
   "source": [
    "# word Toknize\n",
    "tokens_list = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "print(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 품사 부착; Part-of-speech(POS) Tagging\n",
    "- 토큰에 품사 정보를 지정.\n",
    "- [태그 정보]( http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NNP'), ('Kim', 'NNP'), (',', ','), ('How', 'NNP'), ('are', 'VBP'), ('you', 'PRP'), ('?', '.')], [('I', 'PRP'), (\"'m\", 'VBP'), ('fine', 'JJ'), ('.', '.')], [('Thank', 'NNP'), ('you', 'PRP'), (',', ','), ('and', 'CC'), ('you', 'PRP'), ('?', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Pos tagging\n",
    "pos_tagged_tokens = [nltk.pos_tag(tokens) for tokens in tokens_list]\n",
    "print(pos_tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 구문 분석; Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 개체명인식(NER) & Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PERSON Mr./NNP) (PERSON Kim/NNP) ,/, How/NNP are/VBP you/PRP ?/.)\n",
      "(S I/PRP 'm/VBP fine/JJ ./.)\n",
      "(S Thank/NNP you/PRP ,/, and/CC you/PRP ?/.)\n"
     ]
    }
   ],
   "source": [
    "for chunk in nltk.ne_chunk_sents(pos_tagged_tokens):\n",
    "    print(chunk)\n",
    "#     chunk.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. NLP in Korean\n",
    "- [Konlpy](http://konlpy-ko.readthedocs.io/ko/v0.4.3/)\n",
    "- [태그 정보](https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_ver1 = \"철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\"\n",
    "sent_ver2 = \"님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 문장분리; End of Sentence(EOS) Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Kkma # 꼬꼬마 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger_kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수야, 밥 먹었니?', '만약 너가 아직 먹지 않았다면 같이 밥 먹으러 가자. 1 시간 뒤에 정문에서 보자.']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_kkma.sentences(sent_ver1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['님들 한글 자연어처리 어려운 각 ㅇ ㅈ?? ㅇ ㅇ ㅈ ㅋㅋㅋㅋ 한글 파 괘 지리구 옄 ㅋㅋㅋ 띄어쓰기 오지구 옄 ㅋㅋ']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_kkma.sentences(sent_ver2) # 노답..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 토큰화 & 품사 부착; Tokenization & Part-of-speech(POS) Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) 어절단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수야', ',', '밥먹었니', '?', '만약', '너가', '아직', '먹지', '않았다면', '같이', '밥먹으러', '가자', '.', '1시간', '뒤에', '정문에서', '보자', '.']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(sent_ver1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['님들', '한글', '자연어처리', '어려운각', 'ㅇㅈ', '?', '?', 'ㅇ', 'ㅇㅈㅋㅋㅋㅋ', '한글파괘지리구옄ㅋㅋㅋ', '띄어쓰기오지구옄ㅋㅋ']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(sent_ver2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['철수야,', '밥먹었니?', '만약', '너가', '아직', '먹지', '않았다면', '같이', '밥먹으러', '가자.', '1시간', '뒤에', '정문에서', '보자.']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이렇게 해도됨.\n",
    "sent_ver1.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) 형태소단위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '야', ',', '밥', '먹', '었', '니', '?', '만약', '너', '가', '아직', '먹', '지', '않', '았', '다면', '같이', '밥', '먹', '으러', '가', '자', '.', '1', '시간', '뒤', '에', '정문', '에서', '보', '자', '.']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '들', '한글', '자연어', '처리', '어렵', 'ㄴ', '각', 'ㅇ', 'ㅈ', '??', 'ㅇ', 'ㅇ', 'ㅈ', 'ㅋㅋㅋㅋ', '한글', '파', '괘', '지리구', '옄', 'ㅋㅋㅋ', '띄어쓰기', '오', '지구', '옄', 'ㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 단위 분리\n",
    "print(sent_ver1)\n",
    "print(tagger_kkma.morphs(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kkma.morphs(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "[('철수', 'NNG'), ('야', 'JX'), (',', 'SP'), ('밥', 'NNG'), ('먹', 'VV'), ('었', 'EPT'), ('니', 'EFQ'), ('?', 'SF'), ('만약', 'NNG'), ('너', 'NP'), ('가', 'JKS'), ('아직', 'MAG'), ('먹', 'VV'), ('지', 'ECD'), ('않', 'VXV'), ('았', 'EPT'), ('다면', 'ECE'), ('같이', 'MAG'), ('밥', 'NNG'), ('먹', 'VV'), ('으러', 'ECD'), ('가', 'VV'), ('자', 'ECE'), ('.', 'SF'), ('1', 'NR'), ('시간', 'NNG'), ('뒤', 'NNG'), ('에', 'JKM'), ('정문', 'NNG'), ('에서', 'JKM'), ('보', 'VV'), ('자', 'ECE'), ('.', 'SF')]\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "[('님', 'NNG'), ('들', 'XSN'), ('한글', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('어렵', 'VA'), ('ㄴ', 'ETD'), ('각', 'NNG'), ('ㅇ', 'NNG'), ('ㅈ', 'NNG'), ('??', 'SW'), ('ㅇ', 'NNG'), ('ㅇ', 'NNG'), ('ㅈ', 'NNG'), ('ㅋㅋㅋㅋ', 'EMO'), ('한글', 'NNG'), ('파', 'NNG'), ('괘', 'NNG'), ('지리구', 'NNG'), ('옄', 'UN'), ('ㅋㅋㅋ', 'EMO'), ('띄어쓰기', 'NNG'), ('오', 'NNG'), ('지구', 'NNG'), ('옄', 'UN'), ('ㅋㅋ', 'EMO')]\n"
     ]
    }
   ],
   "source": [
    "# 형태소에 POS tagging\n",
    "print(sent_ver1)\n",
    "print(tagger_kkma.pos(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kkma.pos(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '밥', '만약', '너', '1', '1시간', '시간', '뒤', '정문']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '한글', '자연어', '자연어처리', '처리', '각', 'ㅇ', 'ㅇㅈ', 'ㅈ', '한글파괘지리구', '파', '괘', '지리구', '옄', '띄어쓰기', '띄어쓰기오지구옄', '오', '지구']\n"
     ]
    }
   ],
   "source": [
    "# 명사 추출\n",
    "print(sent_ver1)\n",
    "print(tagger_kkma.nouns(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kkma.nouns(sent_ver2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "tagger_kmr = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '야', ',', '밥', '먹', '었', '니', '?', '만약', '너', '가', '아직', '먹', '지', '않', '았', '다면', '같이', '밥', '먹', '으러', '가', '자', '.', '1시간', '뒤', '에', '정문', '에서', '보', '자', '.']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '들', '한글', '자연어', '처리', '어렵', 'ㄴ', '각', 'ㅇㅈ??', 'ㅇ', 'ㅇㅈㅋㅋㅋㅋ', '한글파괘지리구옄ㅋㅋㅋ', '띄어쓰기오지구옄ㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 단위 분리\n",
    "print(sent_ver1)\n",
    "print(tagger_kmr.morphs(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kmr.morphs(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "[('철수', 'NNG'), ('야', 'JKV'), (',', 'SP'), ('밥', 'NNG'), ('먹', 'VV'), ('었', 'EP'), ('니', 'EF'), ('?', 'SF'), ('만약', 'MAG'), ('너', 'NP'), ('가', 'JKS'), ('아직', 'MAG'), ('먹', 'VV'), ('지', 'EC'), ('않', 'VX'), ('았', 'EP'), ('다면', 'EC'), ('같이', 'MAG'), ('밥', 'NNG'), ('먹', 'VV'), ('으러', 'EC'), ('가', 'VV'), ('자', 'EF'), ('.', 'SF'), ('1시간', 'NNP'), ('뒤', 'NNG'), ('에', 'JKB'), ('정문', 'NNG'), ('에서', 'JKB'), ('보', 'VX'), ('자', 'EF'), ('.', 'SF')]\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "[('님', 'NNG'), ('들', 'XSN'), ('한글', 'NNG'), ('자연어', 'NNP'), ('처리', 'NNG'), ('어렵', 'VA'), ('ㄴ', 'ETM'), ('각', 'NNG'), ('ㅇㅈ??', 'NA'), ('ㅇ', 'NA'), ('ㅇㅈㅋㅋㅋㅋ', 'NA'), ('한글파괘지리구옄ㅋㅋㅋ', 'NA'), ('띄어쓰기오지구옄ㅋㅋ', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "# 형태소에 POS tagging\n",
    "print(sent_ver1)\n",
    "print(tagger_kmr.pos(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kmr.pos(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '밥', '밥', '1시간', '뒤', '정문']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '한글', '자연어', '처리', '각']\n"
     ]
    }
   ],
   "source": [
    "# 명사 추출\n",
    "print(sent_ver1)\n",
    "print(tagger_kmr.nouns(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_kmr.nouns(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tagger_mc = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '야', ',', '밥', '먹', '었', '니', '?', '만약', '너', '가', '아직', '먹', '지', '않', '았', '다면', '같이', '밥', '먹', '으러', '가', '자', '.', '1', '시간', '뒤', '에', '정문', '에서', '보', '자', '.']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '들', '한글', '자연어', '처리', '어려운', '각', 'ㅇㅈ', '?', '?', 'ㅇ', 'ㅇㅈㅋㅋㅋㅋ', '한글', '파', '괘', '지리', '구', '옄ㅋㅋㅋ', '띄어쓰', '기', '오지', '구', '옄ㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 단위 분리\n",
    "print(sent_ver1)\n",
    "print(tagger_mc.morphs(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_mc.morphs(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "[('철수', 'NNP'), ('야', 'JKV'), (',', 'SC'), ('밥', 'NNG'), ('먹', 'VV'), ('었', 'EP'), ('니', 'EF'), ('?', 'SF'), ('만약', 'MAG'), ('너', 'NP'), ('가', 'JKS'), ('아직', 'MAG'), ('먹', 'VV'), ('지', 'EC'), ('않', 'VX'), ('았', 'EP'), ('다면', 'EC'), ('같이', 'MAG'), ('밥', 'NNG'), ('먹', 'VV'), ('으러', 'EC'), ('가', 'VX'), ('자', 'EC'), ('.', 'SY'), ('1', 'SN'), ('시간', 'NNBC'), ('뒤', 'NNG'), ('에', 'JKB'), ('정문', 'NNG'), ('에서', 'JKB'), ('보', 'VV'), ('자', 'EF'), ('.', 'SF')]\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "[('님', 'NNG'), ('들', 'XSN'), ('한글', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('어려운', 'VA+ETM'), ('각', 'MM'), ('ㅇㅈ', 'UNKNOWN'), ('?', 'SF'), ('?', 'SY'), ('ㅇ', 'UNKNOWN'), ('ㅇㅈㅋㅋㅋㅋ', 'UNKNOWN'), ('한글', 'NNG'), ('파', 'NNG'), ('괘', 'NNG'), ('지리', 'VV'), ('구', 'EC'), ('옄ㅋㅋㅋ', 'UNKNOWN'), ('띄어쓰', 'VV'), ('기', 'ETN'), ('오지', 'VV'), ('구', 'EC'), ('옄ㅋㅋ', 'UNKNOWN')]\n"
     ]
    }
   ],
   "source": [
    "# 형태소에 POS tagging\n",
    "print(sent_ver1)\n",
    "print(tagger_mc.pos(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_mc.pos(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '밥', '너', '밥', '시간', '뒤', '정문']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님', '한글', '자연어', '처리', '한글', '파', '괘']\n"
     ]
    }
   ],
   "source": [
    "# 명사 추출\n",
    "print(sent_ver1)\n",
    "print(tagger_mc.nouns(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_mc.nouns(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "tagger_twi = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '야', ',', '밥', '먹었', '니', '?', '만약', '너', '가', '아직', '먹지', '않았', '다면', '같이', '밥', '먹으', '러', '가자', '.', '1', '시간', '뒤', '에', '정문', '에서', '보자', '.']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님들', '한글', '자연어', '처리', '어려운', '각', 'ㅇㅈ', '??', 'ㅇ', 'ㅇㅈㅋㅋㅋㅋ', '한글', '파', '괘지리구옄', 'ㅋㅋㅋ', '띄어쓰기', '오지', '구', '옄', 'ㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "# 형태소 단위 분리\n",
    "print(sent_ver1)\n",
    "print(tagger_twi.morphs(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_twi.morphs(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "[('철수', 'Noun'), ('야', 'Josa'), (',', 'Punctuation'), ('밥', 'Noun'), ('먹었', 'Verb'), ('니', 'Eomi'), ('?', 'Punctuation'), ('만약', 'Noun'), ('너', 'Noun'), ('가', 'Josa'), ('아직', 'Noun'), ('먹지', 'Verb'), ('않았', 'Verb'), ('다면', 'Eomi'), ('같이', 'Josa'), ('밥', 'Noun'), ('먹으', 'Verb'), ('러', 'Eomi'), ('가자', 'Verb'), ('.', 'Punctuation'), ('1', 'Number'), ('시간', 'Noun'), ('뒤', 'Noun'), ('에', 'Josa'), ('정문', 'Noun'), ('에서', 'Josa'), ('보자', 'Verb'), ('.', 'Punctuation')]\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "[('님들', 'Noun'), ('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('어려운', 'Adjective'), ('각', 'Noun'), ('ㅇㅈ', 'KoreanParticle'), ('??', 'Punctuation'), ('ㅇ', 'KoreanParticle'), ('ㅇㅈㅋㅋㅋㅋ', 'KoreanParticle'), ('한글', 'Noun'), ('파', 'Noun'), ('괘지리구옄', 'Noun'), ('ㅋㅋㅋ', 'KoreanParticle'), ('띄어쓰기', 'Noun'), ('오지', 'Verb'), ('구', 'Eomi'), ('옄', 'Noun'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "# 형태소에 POS tagging\n",
    "print(sent_ver1)\n",
    "print(tagger_twi.pos(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_twi.pos(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "\n",
      "[('님들', 'Noun'), ('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('어려운', 'Adjective'), ('각', 'Noun'), ('ㅇㅈ', 'KoreanParticle'), ('??', 'Punctuation'), ('ㅇ', 'KoreanParticle'), ('ㅇㅈㅋㅋ', 'KoreanParticle'), ('한글', 'Noun'), ('파괘', 'Noun'), ('지리', 'Noun'), ('구', 'Noun'), ('여', 'Josa'), ('ㅋㅋ', 'KoreanParticle'), ('띄어쓰기', 'Noun'), ('오지', 'Verb'), ('구여', 'Eomi'), ('ㅋㅋ', 'KoreanParticle')]\n",
      "\n",
      "[('님들', 'Noun'), ('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('어렵다', 'Adjective'), ('각', 'Noun'), ('ㅇㅈ', 'KoreanParticle'), ('??', 'Punctuation'), ('ㅇ', 'KoreanParticle'), ('ㅇㅈㅋㅋ', 'KoreanParticle'), ('한글', 'Noun'), ('파괘', 'Noun'), ('지리', 'Noun'), ('구', 'Noun'), ('여', 'Josa'), ('ㅋㅋ', 'KoreanParticle'), ('띄어쓰기', 'Noun'), ('오다', 'Verb'), ('ㅋㅋ', 'KoreanParticle')]\n"
     ]
    }
   ],
   "source": [
    "# 형태소에 POS tagging + Normalize\n",
    "print(sent_ver2)\n",
    "print()\n",
    "print(tagger_twi.pos(sent_ver2, norm=True))\n",
    "print()\n",
    "print(tagger_twi.pos(sent_ver2, norm=True, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "철수야, 밥먹었니? 만약 너가 아직 먹지 않았다면 같이 밥먹으러 가자. 1시간 뒤에 정문에서 보자.\n",
      "['철수', '밥', '만약', '너', '아직', '밥', '시간', '뒤', '정문']\n",
      "\n",
      "님들 한글 자연어처리 어려운각 ㅇㅈ?? ㅇ ㅇㅈㅋㅋㅋㅋ 한글파괘지리구옄ㅋㅋㅋ 띄어쓰기오지구옄ㅋㅋ\n",
      "['님들', '한글', '자연어', '처리', '각', '한글', '파', '괘지리구옄', '띄어쓰기', '옄']\n"
     ]
    }
   ],
   "source": [
    "# 명사 추출\n",
    "print(sent_ver1)\n",
    "print(tagger_twi.nouns(sent_ver1))\n",
    "print()\n",
    "print(sent_ver2)\n",
    "print(tagger_twi.nouns(sent_ver2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. 구문 분석; Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "# 명사가 연속적으로 등장한 후 접미사(suffix)가 선택적으로 붙은 경우를 명사구(NP)로 정의, \n",
    "# 마찬가지 방식으로 동사구(VP)와 형용사구(AP)를 정의\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?}   # Noun phrase\n",
    "VP: {<V.*>*}            # Verb phrase\n",
    "AP: {<A.*>*}            # Adjective phrase\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = \"양념치킨과 후라이드치킨은 둘다 엄청 맛있는 음식이다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_tagged = tagger_kmr.pos(sent)\n",
    "chunks = parser.parse(words_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP 양념치킨/NNP)\n",
      "  과/JC\n",
      "  (NP 후/NNG 라이드/NNP 치킨/NNG)\n",
      "  은/JX\n",
      "  (NP 둘/NR)\n",
      "  다/JX\n",
      "  엄청/MAG\n",
      "  (VP 맛있/VA)\n",
      "  는/ETM\n",
      "  (NP 음식/NNG)\n",
      "  (VP 이/VCP)\n",
      "  다/EF\n",
      "  ./SF)\n"
     ]
    }
   ],
   "source": [
    "chunks.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq = collections.Counter(text_tokenized)\n",
    "vocab = word_freq.most_common(vocab_size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전체 단어 갯수\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.charts.attributes import CatAttr\n",
    "from bokeh.charts import Dot\n",
    "# from bokeh.models import ColumnDataSource, LabelSet\n",
    "# from bokeh.models import HoverTool\n",
    "output_notebook() # 주피터 노트북에서 볼때,\n",
    "#output_file(\"chart.html\") # 주피터노트북이 아닌 html로 출력할때,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'token': [ ele[0] for ele in vocab][2:500],\n",
    "    'freq': [ ele[1] for ele in vocab][2:500]\n",
    "}\n",
    "tools = \"pan,wheel_zoom,box_zoom,reset,resize\"\n",
    "\n",
    "dots = Dot(data, values='freq', label=CatAttr(columns=['token'], sort=False), legend=False, title=\"Python Interpreter Sampling\", width=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
